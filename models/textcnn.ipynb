{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/yxjiang/source/ml_playground\n"
    }
   ],
   "source": [
    "# env setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"/home/yxjiang/source/ml_playground\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Destination folder [/tmp/data] exists.\nTarget file [aclImdb_v1.tar.gz] exists, skip downloading.\nStart to extract [/tmp/data/aclImdb_v1.tar.gz] to [/tmp/data]...\nFile extracted\nProcessing vocabulary from [/tmp/data/aclImdb].\nThere size of vocabulary is : 89527\n"
    }
   ],
   "source": [
    "# data downloading\n",
    "from util import data_util\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# dataset_url=\"https://s3.amazonaws.com/fast-ai-nlp/dbpedia_csv.tgz\"\n",
    "dataset_url=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dest_dir = \"/tmp/data\"\n",
    "dataset_folder_path = os.path.join(dest_dir, \"aclImdb\")\n",
    "data_util.download_data(url=dataset_url, dest_dir=dest_dir)\n",
    "\n",
    "# generate word to id mapping\n",
    "word_to_id, word_list = data_util.get_vocabulary(folder_path=dataset_folder_path, file_suffix=\"vocab\")\n",
    "print(\"There size of vocabulary is :\", len(word_to_id))\n",
    "\n",
    "# generate class id to name mapping\n",
    "# class_to_name = defaultdict(str)\n",
    "# with open(os.path.join(dataset_folder_path, \"classes.txt\"), \"r\") as f:\n",
    "#     for i, class_name in enumerate(f):\n",
    "#         class_to_name[i] = class_name.strip()\n",
    "# print(\"There class mapping:\", class_to_name.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.num_classes = 2\n",
    "        self.sentence_max_length = 30\n",
    "        self.word_embedding_length = 64\n",
    "        self.activation = F.relu\n",
    "        self.criteria = nn.CrossEntropyLoss\n",
    "        self.optimizer = optim.SGD\n",
    "        self.lr = 0.01\n",
    "        self.epochs = 5000\n",
    "        self.batch_size = 2\n",
    "        self.dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform, dataset and dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class CutOrPadTransform:\n",
    "    \"\"\"\n",
    "    Shape all sentences to the equal length.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        if len(input[\"words\"]) >= config.sentence_max_length:\n",
    "            input[\"words\"] = input[\"words\"][:config.sentence_max_length]\n",
    "        else:\n",
    "            input[\"words\"].extend([\" \"] * (config.sentence_max_length - len(input[\"words\"])))\n",
    "        return input\n",
    "\n",
    "\n",
    "class WordsToIdsTransform:\n",
    "    \"\"\"\n",
    "    Convert the list of words to embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, word_to_id):\n",
    "        self.config = config\n",
    "        self.word_to_id = word_to_id\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        input[\"word_ids\"] = torch.tensor([self.word_to_id[w.lower()] for w in input[\"words\"]], dtype=torch.long)\n",
    "        # del input['words']\n",
    "        return input\n",
    "\n",
    "\n",
    "class MovieReviewDataset(Dataset):\n",
    "    def __init__(self, config, pos_data_folder, neg_data_folder, word_to_id, transform):\n",
    "        self.config = config\n",
    "        self.word_to_id = word_to_id\n",
    "        self.data = []\n",
    "        # read all data into memory\n",
    "        for filename in os.listdir(pos_data_folder):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(os.path.join(pos_data_folder, filename), \"r\") as f:\n",
    "                    self.data.append((f.readline(), 1))\n",
    "\n",
    "        for filename in os.listdir(neg_data_folder):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(os.path.join(neg_data_folder, filename), \"r\") as f:\n",
    "                    self.data.append((f.readline(), 0))\n",
    "\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        words = [w.strip() for w in self.data[idx][0].strip().split(\" \")]\n",
    "        label = self.data[idx][1]\n",
    "        input = self.transform({\"words\": words, \"label\": label})\n",
    "        # print(input[\"words\"], \"\\n\", input[\"word_ids\"], \"\\n\", input[\"label\"])\n",
    "        return input[\"words\"], input[\"word_ids\"], input[\"label\"]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, config, vocabulary_size):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = nn.Embedding(vocabulary_size, config.word_embedding_length)\n",
    "        self.hidden_size = 128\n",
    "        self.num_layers = 1\n",
    "        self.directions = 1\n",
    "        self.rnn = nn.RNN(input_size=config.word_embedding_length, hidden_size=self.hidden_size, num_layers=self.num_layers)\n",
    "        self.fc = nn.Linear(in_features=self.hidden_size, out_features=config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = self.embed(x)  # (batch, sentence_length, embedding_dim)\n",
    "        x = x.permute(1, 0, 2).contiguous()  # (sentence_length, batch, embedding_dim)\n",
    "\n",
    "        h0 = torch.zeros((self.num_layers * self.directions, batch, self.hidden_size)).to(device)\n",
    "        output, ht = self.rnn(x, h0)\n",
    "        ht = ht.permute(1, 0, 2)  # (batch, num_layer * directions, embedding_dim)\n",
    "        ht = ht.contiguous().view(batch, self.num_layers * self.directions, self.hidden_size)\n",
    "        x = self.fc(ht)\n",
    "        x = x.view(batch, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, config, vocabulary_size):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed = nn.Embedding(vocabulary_size, config.word_embedding_length)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(1, 1, kernel_size=(3, config.word_embedding_length))\n",
    "        self.conv4 = nn.Conv2d(1, 1, kernel_size=(4, config.word_embedding_length))\n",
    "        self.conv5 = nn.Conv2d(1, 1, kernel_size=(5, config.word_embedding_length))\n",
    "        self.conv6 = nn.Conv2d(1, 1, kernel_size=(6, config.word_embedding_length))\n",
    "        self.conv7 = nn.Conv2d(1, 1, kernel_size=(7, config.word_embedding_length))\n",
    "\n",
    "        self.max_over_time_pool3 = nn.MaxPool2d((config.sentence_max_length - 2, 1))\n",
    "        self.max_over_time_pool4 = nn.MaxPool2d((config.sentence_max_length - 3, 1))\n",
    "        self.max_over_time_pool5 = nn.MaxPool2d((config.sentence_max_length - 4, 1))\n",
    "        self.max_over_time_pool6 = nn.MaxPool2d((config.sentence_max_length - 5, 1))\n",
    "        self.max_over_time_pool7 = nn.MaxPool2d((config.sentence_max_length - 6, 1))\n",
    "\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(5, config.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = torch.unsqueeze(self.embed(x), 1)  # [NCHW], add channel to dimension 1\n",
    "        c = self.conv3(x)\n",
    "        # convs\n",
    "        x1 = self.config.activation(self.conv3(x))\n",
    "        x2 = self.config.activation(self.conv4(x))\n",
    "        x3 = self.config.activation(self.conv5(x))\n",
    "        x4 = self.config.activation(self.conv6(x))\n",
    "        x5 = self.config.activation(self.conv7(x))\n",
    "\n",
    "        # max over time pooling\n",
    "        x1 = self.max_over_time_pool3(x1)\n",
    "        x2 = self.max_over_time_pool4(x2)\n",
    "        x3 = self.max_over_time_pool5(x3)\n",
    "        x4 = self.max_over_time_pool6(x4)\n",
    "        x5 = self.max_over_time_pool7(x5)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=-1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(batch, -1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer\n",
    "def train(model, config, train_dataloader, device, check_interval=1000):\n",
    "    criteria = config.criteria()\n",
    "    optimizer = config.optimizer(model.parameters(), config.lr)\n",
    "    start = time.time()\n",
    "    counts = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        for i, (words, word_ids, labels) in enumerate(train_dataloader):\n",
    "            counts += labels.shape[0]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(word_ids.to(device))\n",
    "            loss = criteria(output, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if ((epoch + 1) * i) % check_interval == 0:\n",
    "                # idx = word_ids[0].cpu().detach().tolist()\n",
    "                # ws = [word_list[i] for i in idx]\n",
    "                # print(ws, word_ids, labels)\n",
    "                print(\"[%d seconds](epoch: %d/%d)[%d samples] loss: %.3f.\" % (time.time() - start, epoch + 1, config.epochs, counts, loss.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ", 'who'] \n tensor([79290, 17846, 27721, 48320, 80687, 66597, 20128, 72972,     0, 53273,\n        23681, 69605, 18839, 27627, 44871, 11244, 38980, 69599, 11244,     0,\n            0,  1587, 69605, 50210, 78662, 11244, 31345, 41253,     0, 30340]) \n 0\n[\"It's\", 'this', 'sort', 'of', 'movie', 'that', 'you', 'try', 'and', 'imitate.', 'By', 'attempting', 'to', 'realise', 'something...', 'then', 'flying', 'through', 'the', 'air', 'almost', 'immediately.', \"I'd\", 'like', 'to', 'do', 'that', 'and', 'I', 'know'] \n tensor([    0, 11147, 34325, 69599, 52388, 78797,  9703,  2308, 69605,     0,\n        86733, 24941,   853,  3027,     0, 33714, 38763,  3297, 11244, 83983,\n        21580,     0, 22144, 39180,   853, 43544, 78797, 69605, 34103, 38113]) \n 1\n['\"Loonatics', 'Unleashed', '\"', 'is', 'the', 'worst', 'thing', 'that', 'could', 'happen', 'to', 'the', 'classic', 'characters', 'created', 'by', 'Chuck', 'Jones', '.', 'The', '\"Loony', 'Tunes\"', 'have', 'many', 'spin', '-offs', 'and', 'different', 'versions', ','] \n tensor([    0, 35190,     0,  1218, 11244, 73920, 73211, 78797, 15723, 51451,\n          853, 11244, 79219, 67350, 22708, 86733, 85107, 49893,     0, 11244,\n            0,     0, 73119, 85165,  9403,     0, 69605, 79199, 13874,     0]) \n 0\n['A', 'dog', 'found', 'in', 'a', 'local', 'kennel', 'is', 'mated', 'with', 'Satan', 'and', 'has', 'a', 'litter', 'of', 'puppies,', 'one', 'of', 'which', 'is', 'given', 'to', 'a', 'family', 'who', 'has', 'just', 'lost', 'their'] \n tensor([84206, 62055, 59553, 44871, 84206,  8684, 49901,  1218, 43730,  6743,\n        48573, 69605, 27721, 84206, 77092, 69599,     0, 70475, 69599, 80138,\n         1218, 33468,   853, 84206, 33368, 30340, 27721, 51609, 39103, 27350]) \n 0\n['I', 'was', 'one', 'of', 'those', '\"few', 'Americans\"', 'that', 'grew', 'up', 'with', 'all', 'of', 'Gerry', \"Andersen's\", 'marvelous', 'creations.', 'Thunderbirds', 'was', 'a', 'great', 'series', 'for', 'the', 'time', 'and', 'would', 'have', 'made', 'a'] \n tensor([34103, 84920, 70475, 69599, 74506,     0,     0, 78797, 38640, 46395,\n         6743, 73957, 69599, 12566,     0, 19054,     0, 32648, 84920, 84206,\n        36051, 18636, 76338, 11244, 63669, 69605, 33500, 73119, 79731, 84206]) \n 0\n['This', 'sci-fi', 'masterpiece', 'has', 'too', 'many', 'flaws', 'after', 'the', 'editors', 'had', 'butchered', 'it', 'after', 'its', 'opening', 'in', '1936.', 'Visually', 'it', 'is', 'a', 'wonder', 'to', 'behold,', 'but', 'the', 'script', 'allows', 'too'] \n tensor([11147, 73993, 20363, 27721, 47815, 85165, 83459, 45882, 11244, 12961,\n        64091, 73874, 38873, 45882, 38263, 74416, 44871,     0,  9189, 38873,\n         1218, 84206, 25915,   853,     0, 40188, 11244, 53058, 65938, 47815]) \n 1\n['The', 'Williams', 'family', 'live', 'on', 'a', 'ranch', 'located', 'in', 'the', 'middle', 'of', 'the', 'remote', 'desert.', 'They', 'find', 'themselves', 'in', 'considerable', 'peril', 'when', 'the', 'place', 'is', 'suddenly', 'thrust', 'into', 'a', 'time'] \n tensor([11244, 79094, 33368, 89429, 40823, 84206, 78050, 61624, 44871, 11244,\n        38980, 69599, 11244, 19420,     0, 50644, 57229, 77826, 44871, 62437,\n        53207, 15118, 11244, 10382,  1218, 20900,  4289, 63534, 84206, 63669]) \n 1\n['In', 'Don', \"Siegel's\", '1971', 'masterpiece', '\"Dirty', 'Harry\",', 'Clint', 'Eastwood', 'epitomized', 'the', 'super-tough,', 'super-cool', 'unorthodox,', 'no-nonsense', 'cinema-cop', 'with', 'his', 'role', 'of', 'the', 'eponymous', 'Inspector', \"'Dirty'\", 'Harry', 'Callahan.', 'Two', 'sequels', 'followed,', 'the'] \n tensor([44871, 66230,     0,     0, 20363,     0,     0, 48814, 13814,  8779,\n        11244,     0, 87463,     0, 45385, 29537,  6743, 79712, 36114, 69599,\n        11244, 35195, 46855,     0, 41568,     0, 37084, 10782,     0, 11244]) \n 1\n['This', 'is', 'no', 'art-house', 'film,', \"it's\", 'mainstream', 'entertainment.', '<br', '/><br', \"/>Lot's\", 'of', 'beautiful', 'people,', 't&a,', 'and', 'action.', 'I', 'found', 'it', 'very', 'entertaining.', \"It's\", 'not', 'supposed', 'to', 'be', 'intellectually', 'stimulating,', \"it's\"] \n tensor([11147,  1218, 80137, 72680,     0,     0, 29912,     0,     0,     0,\n            0, 69599, 18819,     0,     0, 69605,     0, 34103, 59553, 38873,\n        82313,     0,     0, 52165, 26162,   853, 48789,  7379,     0,     0]) \n 1\n['the', 'only', 'enjoyable', 'thing', 'about', 'this', 'highly', 'mockable', 'movie', 'is', 'playing', '\"guess\"', 'that', 'location.', 'What', 'Toronto', 'landmark', 'will', 'stand', 'in', 'for', 'what', 'American/international', 'location.<br', '/><br', '/>who', 'knew', 'that', 'the', 'anti-christ'] \n tensor([11244, 32657,  1500, 73211, 32839, 11147, 57112, 51352, 52388,  1218,\n        56085,     0, 78797,     0, 25983, 22955, 86886, 35669,  6587, 44871,\n        76338, 25983,     0,     0,     0,     0, 23456, 78797, 11244, 13883]) \n 0\n['A', 'DOUBLE', 'LIFE', 'has', 'developed', 'a', 'mystique', 'among', 'film', 'fans', 'for', 'two', 'reasons:', 'the', 'plot', 'idea', 'of', 'an', 'actor', 'getting', 'so', 'wrapped', 'up', 'into', 'a', 'role', '(here', 'Othello)', 'as', 'to'] \n tensor([84206, 81960, 81908, 27721,  8876, 84206, 73341, 26259, 49204, 65617,\n        76338, 37084,     0, 11244, 20078,  4266, 69599, 53273,  4986, 75478,\n        54079, 76431, 46395, 63534, 84206, 36114,     0,     0,  3503,   853]) \n 1\n['At', 'the', 'beginning', 'of', 'the', 'movie,', 'the', 'beautiful', 'photography', 'and', 'the', 'scenes', 'of', 'the', 'fox', 'were', 'amazing.', 'However,', 'the', 'story', 'was', 'so', 'very', 'slow', 'and', 'boring.', 'And', 'then', 'the', 'little'] \n tensor([64119, 11244, 46001, 69599, 11244,     0, 11244, 18819, 42596, 69605,\n        11244, 78473, 69599, 11244, 40913, 69907,     0,     0, 11244, 21922,\n        84920, 54079, 82313, 65105, 69605,     0, 69605, 33714, 11244, 84247]) \n 0\n['Yeah', 'i', 'saw', 'the', 'rough', 'cuts.', 'The', 'unedited', 'sex', 'scenes.', 'The', 'dire', 'cut', 'scenes.', 'Almost', 'on', 'a', 'par', 'with', 'the', 'film', \"'The\", \"Need'\", 'for', 'awful', 'acting.', 'This', 'movie', 'is', 'as'] \n tensor([19675, 34103, 54560, 11244, 33682,     0, 11244, 23577, 80348,     0,\n        11244, 82305, 68742,     0, 21580, 40823, 84206, 51765,  6743, 11244,\n        49204,     0,     0, 76338, 63323,     0, 11147, 52388,  1218,  3503]) \n 0\n[\"It's\", 'hard', 'for', 'me', 'to', 'assign', 'the', '\"fair\"', 'number', 'of', 'stars', 'to', 'this', 'film,', 'but', 'I', 'settled', 'on', '8', 'because', 'of', 'its', 'high', 'production', 'values', 'and', 'what', 'was,', 'in', '1968,'] \n tensor([    0, 65525, 76338, 70942,   853, 39394, 11244,     0, 74796, 69599,\n        43427,   853, 11147,     0, 40188, 34103, 54940, 40823,     0, 71345,\n        69599, 38263, 28393, 59132,  4276, 69605, 25983,     0, 44871,     0]) \n 1\n['OK,', 'I', 'am', 'blessed.', 'I', 'have', 'seen', 'two', 'very', 'strong', 'stage', 'productions,', 'the', 'one', 'in', 'New', 'York', 'with', 'the', 'original', 'cast,', 'and', 'another', 'at', 'the', 'San', 'Diego', 'Rep', '(Rosina', 'Reynolds'] \n tensor([    0, 34103, 37553,     0, 34103, 73119, 68266, 37084, 82313, 79067,\n        13495,     0, 11244, 70475, 44871, 57433, 30982,  6743, 11244, 38847,\n            0, 69605, 81043, 64119, 11244, 21976, 43842, 26377,     0,  4670]) \n 0\n['Just', 'like', 'last', 'years', 'event', 'WWE', 'New', 'Years', 'Revolution', '2006', 'was', 'headlined', 'by', 'an', 'Elimination', 'Chamber', 'match.', 'The', 'difference', 'between', 'last', 'years', 'and', 'this', 'years', 'match', 'however', 'was', 'the', 'entertainment'] \n tensor([51609, 39180, 32041,  5028, 18106, 37605, 57433,  5028,  6452,     0,\n        84920,  6183, 86733, 53273, 67022,  6335,     0, 11244, 57779, 41628,\n        32041,  5028, 69605, 11147,  5028, 83781, 70934, 84920, 11244, 38409]) \n 0\n['With', 'lots', 'of', 'sunshine,', 'gauzy', 'light', 'and', 'shadow', 'filtering', 'through', 'windows', 'and', 'into', 'rooms,', 'tracking', 'shots', 'moving', 'through', 'crowds', 'with', 'hand-held', 'camera,', 'quick-paced', 'editing', 'and', 'extreme', 'close-ups', 'here', 'and', 'there,'] \n tensor([ 6743, 18498, 69599,     0, 48992, 44967, 69605,  3059, 59118,  3297,\n        10878, 69605, 63534,     0, 11081, 23370, 82060,  3297, 76359,  6743,\n        62829,     0, 58788, 66992, 69605, 63764, 32321, 30378, 69605,     0]) \n 1\n['Fragglerock', 'is', 'excellent', 'in', 'the', 'way', 'that', \"Schindler's\", 'List', 'was', 'excellent.', 'A', 'Great', 'watch', 'for', 'children', 'and', 'adults', 'of', 'all', 'genders.', 'Big', 'noses', 'can', 'be', 'seen', 'as', 'hinting', 'towards', 'phallic'] \n tensor([17789,  1218, 80650, 44871, 11244, 33179, 78797,     0, 63224, 84920,\n            0, 84206, 36051, 62115, 76338, 11907, 69605, 69130, 69599, 73957,\n            0, 84171, 77839, 54415, 48789, 68266,  3503, 84593,  1921, 62466]) \n 1\n[\"I'm\", 'glad', 'some', 'people', 'liked', 'this,', 'but', 'I', 'hated', 'this', 'film.', 'It', 'had', 'a', 'very', 'good', 'idea', 'for', 'a', 'story', 'line,', 'but', \"that's\", 'where', 'it', 'ended.', 'It', 'was', 'badly', 'written,'] \n tensor([83788, 86437, 43438, 36936, 56876,     0, 40188, 34103, 17568, 11147,\n            0, 38873, 64091, 84206, 82313, 85533,  4266, 76338, 84206, 21922,\n            0, 40188,     0, 29632, 38873,     0, 38873, 84920, 52949,     0]) \n 0\n['The', 'acting', 'in', 'this', 'movie', 'stinks.', 'The', 'plot', 'makes', 'very', 'little', 'sense,', 'but', 'from', 'what', 'I', 'gathered', \"it's\", 'supposed', 'to', 'be', 'about', 'this', 'scientist', 'who', 'develops', 'the', 'ability', 'to', 'turn'] \n tensor([11244, 48093, 44871, 11147, 52388,     0, 11244, 20078, 62383, 82313,\n        84247,     0, 40188, 80687, 25983, 34103, 48934,     0, 26162,   853,\n        48789, 32839, 11147,  2613, 30340, 57205, 11244, 77157,   853,  8025]) \n 0\n['This', 'movie', 'is', 'AWFUL!', 'I', \"don't\", 'even', 'know', 'where', 'to', 'begin,', \"I'm\", 'speechless', 'I', \"can't\", 'even', 'describe', 'how', 'awful', 'this', 'is.', 'The', 'blood', 'is', 'flourescent', 'first', 'of', 'all,', 'and', 'the'] \n tensor([11147, 52388,  1218,     0, 34103, 77552, 85140, 38113, 29632,   853,\n            0, 83788, 50330, 34103, 14223, 85140, 78049, 53175, 63323, 11147,\n            0, 11244, 20187,  1218, 63204, 16006, 69599,     0, 69605, 11244]) \n 0\n['I', 'enjoy', 'watching', 'western', 'films', 'but', 'this', 'movie', 'takes', 'the', 'biscuit.', 'The', 'script', 'and', 'dialogue', 'is', 'laughable.', 'The', 'acting', 'was', 'awful,', 'where', 'did', 'they', 'get', 'them', 'from?', 'Music', 'was', 'OK'] \n tensor([34103,  8735, 50281, 76522, 51875, 40188, 11147, 52388, 50412, 11244,\n            0, 11244, 53058, 69605, 34600,  1218,     0, 11244, 48093, 84920,\n            0, 29632,  8762, 50644, 61759, 83699,     0, 62238, 84920, 79373]) \n 0\n['This', 'is', 'one', 'of', 'the', 'best', 'movie', 'I', 'have', 'ever', 'seen.', 'My', 'parents', 'comes', 'from', 'rural', 'India', 'and', 'to', 'some', 'extend', 'I', 'have', 'seen', 'the', 'life', 'of', 'the', 'villagers.', 'Peoples'] \n tensor([11147,  1218, 70475, 69599, 11244, 52918, 52388, 34103, 73119, 51547,\n            0, 66542, 84302,  3276, 80687, 28718,  9198, 69605,   853, 43438,\n        25803, 34103, 73119, 68266, 11244, 81908, 69599, 11244,     0, 77508]) \n 1\n['The', 'memory', 'of', 'the', '\"The', 'Last', 'Hunt\"', 'has', 'stuck', 'with', 'me', 'since', 'I', 'saw', 'it', 'in', '1956', 'when', 'I', 'was', '13.', 'It', 'is', 'a', 'movie', 'that', 'was', 'far', 'ahead', 'of'] \n tensor([11244,  3756, 69599, 11244,     0, 32041,     0, 27721, 16694,  6743,\n        70942, 21436, 34103, 54560, 38873, 44871,     0, 15118, 34103, 84920,\n            0, 38873,  1218, 84206, 52388, 78797, 84920, 13310, 27375, 69599]) \n 1\n['Although', 'Cinderella', \"isn't\", 'the', 'obvious', 'choice', 'for', 'a', 'sequel', 'I', 'love', 'Jaq', 'and', 'Gus', 'so', 'I', \"didn't\", 'hesitate.', 'The', 'format', 'of', 'the', 'mice', 'writing', 'a', 'book', 'for', 'Cinderella', 'was', 'an'] \n tensor([13832, 65091, 52887, 11244, 11687, 49754, 76338, 84206, 52812, 34103,\n        43699, 28987, 69605,  4044, 54079, 34103, 17329,     0, 11244, 76347,\n        69599, 11244, 84843, 38142, 84206, 75578, 76338, 65091, 84920, 53273]) \n 1\n['Contrary', 'to', 'most', 'other', 'commentators,', 'I', 'deeply', 'hate', 'this', 'series.<br', '/><br', '/>It', 'starts', 'out', 'looking', 'interesting,', 'with', 'mysterious', 'aliens', 'and', 'giant', 'robots,', 'and', 'I', 'kept', 'my', 'hopes', 'up', 'until', 'the'] \n tensor([73095,   853, 54169, 53516,     0, 34103, 77895, 51357, 11147,     0,\n            0,     0,  3724,  9318, 60795,     0,  6743, 31345, 38833, 69605,\n        83176,     0, 69605, 34103, 26573, 66542, 36578, 46395, 12449, 11244]) \n 0\n['Although', 'at', 'one', 'point', 'I', 'thought', 'this', 'was', 'going', 'to', 'turn', 'into', 'The', 'Graduate,', 'I', 'have', 'to', 'say', 'that', 'The', 'Mother', 'does', 'an', 'excellent', 'job', 'of', 'explaining', 'the', 'sexual', 'desires'] \n tensor([13832, 64119, 70475, 44043, 34103, 71663, 11147, 84920, 78142,   853,\n         8025, 63534, 11244,     0, 34103, 73119,   853, 55588, 78797, 11244,\n        33418, 55803, 53273, 80650, 76732, 69599, 19713, 11244, 78996, 29359]) \n 1\n['After', 'seeing', 'all', 'the', 'Jesse', 'James,', 'Quantrill,', 'jayhawkers,etc', 'films', 'in', 'the', 'fifties,', 'it', 'is', 'quite', 'a', 'thrill', 'to', 'see', 'this', 'film', 'with', 'a', 'new', 'perspective', 'by', 'director', 'Ang', 'Lee.', 'The'] \n tensor([45882, 88749, 73957, 11244, 22383,     0,     0,     0, 51875, 44871,\n        11244,     0, 38873,  1218, 38173, 84206, 18630,   853, 22369, 11147,\n        49204,  6743, 84206, 57433, 12383, 86733,  7294, 46662,     0, 11244]) \n 1\n['Worst', 'film', 'ever,', 'this', 'is', 'a', 'statement', 'that', 'people', 'here', 'on', 'IMDb', 'often', 'throw', 'around.', 'Whether', \"it's\", 'an', 'Uwe', 'Boll', 'movie,', 'bad', 'classics', 'like', 'Manos', 'The', 'Hands', 'Of', 'Fate', 'or'] \n tensor([73920, 49204,     0, 11147,  1218, 84206, 77633, 78797, 36936, 30378,\n        40823, 12430, 56137,  7592,     0, 16506,     0, 53273, 14983, 12825,\n            0, 88307, 86449, 39180, 82308, 11244, 18407, 69599, 46034, 32826]) \n 0\n['Branagh', 'and', 'Fishburne', 'deliver', 'excellent', 'performances', 'in', 'this', 'version', 'of', 'the', 'Shakespeare', 'classic.', 'Branagh', 'plays', 'Iago', 'better', 'than', \"I've\", 'seen', 'the', 'character', 'played', 'in', 'film', 'or', 'on', 'stage.', 'Some', 'might'] \n tensor([85803, 69605, 56027,  8039, 80650, 21394, 44871, 11147, 42564, 69599,\n        11244, 39547,     0, 85803, 75629, 75950, 46284,  6658, 48465, 68266,\n        11244,  3042, 27014, 44871, 49204, 32826, 40823,     0, 43438, 11586]) \n 1\n['in', 'a', 'not', 'so', 'conventional', 'sense', 'of', 'the', 'word.<br', '/><br', '/>This', 'movie', 'was', 'one', 'of', 'my', 'favorites', 'as', 'a', 'young', 'child,', 'and', 'I', 'just', 'recently', 'remembered', 'it,', 'and', 'thought', 'to'] \n tensor([44871, 84206, 52165, 54079, 55781, 31266, 69599, 11244,     0,     0,\n            0, 52388, 84920, 70475, 69599, 66542, 49719,  3503, 84206, 14065,\n            0, 69605, 34103, 51609, 42283, 35558,     0, 69605, 71663,   853]) \n 1\n['Where', 'do', 'I', 'start?', 'Per', 'the', 'title', 'of', 'this', 'film', 'I', 'expected', 'some', 'degree', 'of', 'authenticity,', 'in', 'the', 'end', 'I', 'was', 'severally', 'let', 'down.', 'This', 'is', 'not', 'the', 'story', 'of'] \n tensor([29632, 43544, 34103,     0, 82751, 11244, 83934, 69599, 11147, 49204,\n        34103, 57132, 43438,  4156, 69599,     0, 44871, 11244,  7963, 34103,\n        84920, 54303, 85884,     0, 11147,  1218, 52165, 11244, 21922, 69599]) \n 0\n['A', 'scientist', '(John', 'Carradine--sadly)', 'finds', 'out', 'how', 'to', 'bring', 'the', 'dead', 'back', 'to', 'life.', 'However', 'they', 'come', 'back', 'with', 'faces', 'of', 'marble.', 'Eventually', 'this', 'all', 'leads', 'to', 'disaster.<br', '/><br', '/>Boring,'] \n tensor([84206,  2613,     0,     0,  5060,  9318, 53175,   853, 77525, 11244,\n        88312, 87903,   853,     0, 70934, 50644, 80971, 87903,  6743, 14187,\n        69599,     0, 15899, 11147, 73957, 40681,   853,     0,     0,     0]) \n 0\n['I', \"can't\", 'believe', 'I', 'am', 'so', 'angry', 'after', 'seeing', 'this', 'that', 'I', 'am', 'about', 'to', 'write', 'my', 'first', 'ever', 'review', 'on', 'IMDb.<br', '/><br', '/>This', 'Disney', 'documentary', 'is', 'nothing', 'but', 'a'] \n tensor([34103, 14223, 13323, 34103, 37553, 54079, 69349, 45882, 88749, 11147,\n        78797, 34103, 37553, 32839,   853, 77548, 66542, 16006, 51547, 82413,\n        40823,     0,     0,     0, 19295, 16134,  1218,  1604, 40188, 84206]) \n 0\n['This', 'is', 'a', 'thriller', 'with', 'a', 'good', 'concept,', 'good', 'acting,', 'good', 'photography', 'and', 'good', 'intentions', 'all', 'around,', 'but', 'which', 'is', 'confused', 'and', 'disjointed', 'in', 'execution.<br', '/><br', '/>Garcia', 'stars', 'as', 'John'] \n tensor([11147,  1218, 84206,  5037,  6743, 84206, 85533,     0, 85533,     0,\n        85533, 42596, 69605, 85533, 15966, 73957,     0, 40188, 80138,  1218,\n        70604, 69605, 53395, 44871,     0,     0,     0, 43427,  3503, 79830]) \n 0\n['Being', 'a', 'transplanted', 'New', 'Yorker,', 'I', 'might', 'be', 'more', 'critical', 'than', 'most', 'in', 'watching', 'City', 'Hall.', 'But', 'I', 'have', 'to', 'say', 'that', 'before', 'even', 'getting', 'to', 'the', 'story', 'itself', 'I'] \n tensor([87873, 84206, 77329, 57433,     0, 34103, 11586, 48789, 82690,   726,\n         6658, 54169, 44871, 50281, 71950,     0, 40188, 34103, 73119,   853,\n        55588, 78797, 28671, 85140, 75478,   853, 11244, 21922,  1103, 34103]) \n 1\n['Yeah,', 'unfortunately', 'I', 'came', 'across', 'the', 'DVD', 'of', 'this', 'and', 'found', 'that', 'it', 'was', 'incredibly', 'awful.<br', '/><br', '/>First', 'of', 'all,', 'the', 'characters', 'suck.', 'I', 'mean,', 'come', 'on,', 'if', 'some', 'dork'] \n tensor([    0,  1459, 34103, 83075, 73599, 11244, 82538, 69599, 11147, 69605,\n        59553, 78797, 38873, 84920, 72660,     0,     0,     0, 69599,     0,\n        11244, 67350,     0, 34103,     0, 80971,     0,  5347, 43438, 22799]) \n 0\n['A', 'few', 'summer', 'space', 'campers', 'actually', 'were', 'accidently', 'sent', 'into', 'space', 'by', 'a', 'robot.', 'And', 'the', 'oxygen', 'in', 'ship', 'was', 'running', 'short.', 'They', 'had', 'to', 'sent', 'someone', 'to', 'a', 'space'] \n tensor([84206, 12161, 86518, 37743, 11872, 57386, 69907, 20535, 67495, 63534,\n        37743, 86733, 84206,     0, 69605, 11244, 72642, 44871, 33916, 84920,\n        71875,     0, 50644, 64091,   853, 67495, 78696,   853, 84206, 37743]) \n 1\n['This', 'German', 'documentary,', 'in', 'English,', 'is', 'about', 'a', 'Scottish', 'environmental', 'sculptor', 'named', 'Andy', 'Goldsworthy.', 'He', 'makes', 'art', 'from', 'objects', 'he', 'finds', 'in', 'nature.', 'For', 'example,', 'early', 'in', 'the', 'film', 'we'] \n tensor([11147,  6038,     0, 44871,     0,  1218, 32839, 84206, 62876, 47305,\n        75371, 48494, 41819,     0, 84142, 62383, 48594, 80687, 26020, 84142,\n         5060, 44871,     0, 76338,     0, 39944, 44871, 11244, 49204, 45226]) \n 1\n['Richard', 'Farnsworth', 'is', 'one', 'of', 'my', 'favorite', 'actors.', 'He', 'usually', 'gives', 'solid', 'performances,', 'such', 'as', 'in', 'The', 'Straight', 'Story,', 'and', 'The', 'Grey', 'Fox.', 'He', 'also', 'does', 'fairly', 'well', 'here,', 'but'] \n tensor([52679, 63586,  1218, 70475, 69599, 66542, 14415,     0, 84142, 54817,\n        83845, 50338,     0, 46814,  3503, 44871, 11244, 81565,     0, 69605,\n        11244, 43071,     0, 84142, 27195, 55803, 66771, 73824,     0, 40188]) \n 0\n['I', 'had', 'never', 'heard', 'of', 'this', 'Adam', 'Sandler', 'movie', 'until', 'I', 'saw', 'it', 'on', 'the', 'wall', 'at', 'Blockbuster.', 'Being', 'an', 'Adam', 'Sandler', 'fan', 'at', 'the', 'time,', 'I', 'rented', 'it.', 'HONESTLY'] \n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-97c6e1fce932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-0ea6e82225d0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, config, train_dataloader, device, check_interval)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mcounts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1d99b5f2191c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0msuffixes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'names={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_add_suffixes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_newline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_add_suffixes\u001b[0;34m(tensor_str, suffixes, indent, force_newline)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mtensor_strs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mlast_line_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0msuffix_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_newline\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlast_line_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# put everything together\n",
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = Config()\n",
    "\n",
    "pos_data_folder = os.path.join(dataset_folder_path, \"train/pos\")\n",
    "neg_data_folder = os.path.join(dataset_folder_path, \"train/neg\")\n",
    "train_dataset = MovieReviewDataset(config, pos_data_folder, neg_data_folder, word_to_id, \n",
    "                            transform=transforms.Compose([\n",
    "                                CutOrPadTransform(config), WordsToIdsTransform(config, word_to_id)\n",
    "                            ]))\n",
    "dataloader = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# model = TextCNN(config, len(word_to_id)).to(device)\n",
    "model = RNN(config, len(word_list)).to(device)\n",
    "\n",
    "train(model, config, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 3, 7]) torch.Size([1, 3, 7])\ntensor([[[-0.6205,  0.8133, -0.2291,  0.7881, -0.5221, -0.5650,  0.3169],\n         [-0.0421, -0.1698,  0.4719,  0.4474, -0.1437, -0.0701,  0.5606],\n         [ 0.3918, -0.0828, -0.3640,  0.2610,  0.4248,  0.8207, -0.5132]]],\n       grad_fn=<StackBackward>)\ntensor([[[ 0.6937,  0.4441, -0.3771,  0.4462, -0.5602, -0.0196, -0.2659],\n         [-0.3431,  0.5107, -0.7487,  0.7184,  0.7843, -0.0246, -0.1306],\n         [ 0.2353, -0.8312,  0.1603, -0.3758,  0.0087, -0.7784, -0.9561]],\n\n        [[-0.8158,  0.6252, -0.7030,  0.5025, -0.2198, -0.7257, -0.5358],\n         [-0.6847, -0.3237,  0.5203,  0.5507, -0.6944, -0.3100, -0.2738],\n         [ 0.4111, -0.8770,  0.5370, -0.2157, -0.1740,  0.2111,  0.4982]],\n\n        [[ 0.0787, -0.0141,  0.6000,  0.6017, -0.4545,  0.0529,  0.2032],\n         [ 0.1149,  0.3421, -0.0415,  0.4033, -0.2639, -0.4638,  0.1652],\n         [-0.9416,  0.7988, -0.5959, -0.2201, -0.4038, -0.0768,  0.6462]],\n\n        [[-0.3865,  0.8236, -0.5943,  0.3197,  0.0092, -0.1541,  0.0833],\n         [-0.4911, -0.6199,  0.0719,  0.4413, -0.2063, -0.5761, -0.5387],\n         [ 0.4754,  0.9045,  0.0657,  0.0619, -0.3475,  0.7142, -0.1917]],\n\n        [[-0.6205,  0.8133, -0.2291,  0.7881, -0.5221, -0.5650,  0.3169],\n         [-0.0421, -0.1698,  0.4719,  0.4474, -0.1437, -0.0701,  0.5606],\n         [ 0.3918, -0.0828, -0.3640,  0.2610,  0.4248,  0.8207, -0.5132]]],\n       grad_fn=<StackBackward>)\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sentence_length = 5\n",
    "batch_size = 3\n",
    "input_dim = 6\n",
    "num_direction = 1\n",
    "layer = 1\n",
    "hidden_size = 7\n",
    "\n",
    "rnn = nn.RNN(input_dim, hidden_size, layer)\n",
    "x = torch.randn(sentence_length, batch_size, input_dim)\n",
    "h0 = torch.randn(num_direction * layer, batch_size, hidden_size)\n",
    "\n",
    "output, hn = rnn(x, h0)\n",
    "print(output.shape, hn.shape)\n",
    "\n",
    "print(hn)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}