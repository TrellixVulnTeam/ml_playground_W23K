{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/yxjiang/source/ml_playground\n"
    }
   ],
   "source": [
    "# data downloading\n",
    "import data_util\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"/home/yxjiang/source/ml_playground\")\n",
    "print(os.getcwd())\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Destination folder [/tmp/data] exists.\nTarget file [aclImdb_v1.tar.gz] exists, skip downloading.\nStart to extract [/tmp/data/aclImdb_v1.tar.gz] to [/tmp/data]...\nFile extracted\nProcessing vocabulary from [/tmp/data/aclImdb].\nThere size of vocabulary is : 89527\n"
    }
   ],
   "source": [
    "dataset_url=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dest_dir = \"/tmp/data\"\n",
    "dataset_folder_path = os.path.join(dest_dir, \"aclImdb\")\n",
    "data_util.download_data(url=dataset_url, dest_dir=dest_dir)\n",
    "\n",
    "# generate word to id mapping\n",
    "word_to_id, word_list = data_util.get_vocabulary(folder_path=dataset_folder_path, file_suffix=\"vocab\")\n",
    "print(\"There size of vocabulary is :\", len(word_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, config, vocabulary_size):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn_type = config.rnn_type\n",
    "        self.embed = nn.Embedding(vocabulary_size, config.word_embedding_length)\n",
    "        self.num_layers = 1\n",
    "        self.directions = 1\n",
    "        self.hidden_size = 128\n",
    "        if config.rnn_type is nn.RNN:\n",
    "            self.rnn = nn.RNN(\n",
    "                input_size=config.word_embedding_length, \n",
    "                hidden_size=self.hidden_size, \n",
    "                num_layers=self.num_layers\n",
    "            )\n",
    "        elif config.rnn_type is nn.LSTM:\n",
    "            self.cell_size = 128\n",
    "            self.rnn = nn.LSTM(\n",
    "                input_size=config.word_embedding_length,\n",
    "                hidden_size=self.hidden_size,\n",
    "                num_layers=self.num_layers\n",
    "            )\n",
    "        elif config.rnn_type is nn.GRU:\n",
    "            self.rnn = nn.GRU(\n",
    "                input_size=config.word_embedding_length, \n",
    "                hidden_size=self.hidden_size, \n",
    "                num_layers=self.num_layers\n",
    "            )\n",
    "        self.fc1 = nn.Linear(in_features=self.hidden_size, out_features=64)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = self.embed(x)  # (batch, sentence_length, embedding_dim)\n",
    "        x = x.permute(1, 0, 2).contiguous()  # (sentence_length, batch, embedding_dim)\n",
    "\n",
    "        h0 = torch.zeros((self.num_layers * self.directions, batch, self.hidden_size)).to(self.config.device)\n",
    "        if self.rnn_type is nn.RNN or self.rnn_type is nn.GRU:\n",
    "            output, ht = self.rnn(x, h0)\n",
    "        elif self.rnn_type is nn.LSTM:\n",
    "            c0 = torch.zeros((self.num_layers * self.directions, batch, self.hidden_size)).to(self.config.device)\n",
    "            output, (ht, ct) = self.rnn(x, (h0, c0))\n",
    "        ht = ht.view(self.num_layers, self.directions, ht.shape[1], -1) # decompose layers and directions\n",
    "        ht = ht[-1]  # get last layer and remove layer dimension\n",
    "        ht = ht.permute(1, 0, 2)  # (batch, directions, embedding_dim)\n",
    "        ht = ht.contiguous().view(batch, self.directions, self.hidden_size)\n",
    "        x = F.relu(self.fc1(ht))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(batch, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sentence_max_len_40-embedding-128-model-<class 'torch.nn.modules.rnn.GRU'>-layers-5-lr-0.00001000-batch_size-1024-dropout-0.10\n[1 seconds](epoch: 0/500)[25000 samples] loss: 0.701.\neval loss: 0.698, accuracy: 50.092% [12523/25000]\n[97 seconds](epoch: 50/500)[1275000 samples] loss: 0.686.\neval loss: 0.692, accuracy: 52.372% [13093/25000]\n[193 seconds](epoch: 100/500)[2525000 samples] loss: 0.682.\neval loss: 0.688, accuracy: 54.016% [13504/25000]\n[289 seconds](epoch: 150/500)[3775000 samples] loss: 0.634.\neval loss: 0.646, accuracy: 62.596% [15649/25000]\n[385 seconds](epoch: 200/500)[5025000 samples] loss: 0.585.\neval loss: 0.611, accuracy: 66.500% [16625/25000]\n[480 seconds](epoch: 250/500)[6275000 samples] loss: 0.490.\neval loss: 0.592, accuracy: 68.452% [17113/25000]\n[576 seconds](epoch: 300/500)[7525000 samples] loss: 0.493.\neval loss: 0.586, accuracy: 69.300% [17325/25000]\n[671 seconds](epoch: 350/500)[8775000 samples] loss: 0.436.\neval loss: 0.590, accuracy: 69.748% [17437/25000]\n[767 seconds](epoch: 400/500)[10025000 samples] loss: 0.448.\neval loss: 0.599, accuracy: 70.076% [17519/25000]\n[862 seconds](epoch: 450/500)[11275000 samples] loss: 0.359.\neval loss: 0.613, accuracy: 70.280% [17570/25000]\n[956 seconds](epoch: 499/500)[12500000 samples] loss: 0.390.\neval loss: 0.634, accuracy: 70.264% [17566/25000]\nsentence_max_len_40-embedding-128-model-<class 'torch.nn.modules.rnn.GRU'>-layers-10-lr-0.00001000-batch_size-1024-dropout-0.10\n[1 seconds](epoch: 0/500)[25000 samples] loss: 0.694.\neval loss: 0.694, accuracy: 50.612% [12653/25000]\n[98 seconds](epoch: 50/500)[1275000 samples] loss: 0.684.\neval loss: 0.692, accuracy: 52.556% [13139/25000]\n[194 seconds](epoch: 100/500)[2525000 samples] loss: 0.678.\neval loss: 0.689, accuracy: 53.880% [13470/25000]\n[288 seconds](epoch: 150/500)[3775000 samples] loss: 0.634.\neval loss: 0.648, accuracy: 62.540% [15635/25000]\n[384 seconds](epoch: 200/500)[5025000 samples] loss: 0.591.\neval loss: 0.614, accuracy: 66.308% [16577/25000]\n[480 seconds](epoch: 250/500)[6275000 samples] loss: 0.544.\neval loss: 0.594, accuracy: 68.356% [17089/25000]\n[576 seconds](epoch: 300/500)[7525000 samples] loss: 0.474.\neval loss: 0.586, accuracy: 69.284% [17321/25000]\n[672 seconds](epoch: 350/500)[8775000 samples] loss: 0.462.\neval loss: 0.588, accuracy: 69.628% [17407/25000]\n[768 seconds](epoch: 400/500)[10025000 samples] loss: 0.433.\neval loss: 0.597, accuracy: 69.960% [17490/25000]\n[864 seconds](epoch: 450/500)[11275000 samples] loss: 0.392.\neval loss: 0.612, accuracy: 69.984% [17496/25000]\n[957 seconds](epoch: 499/500)[12500000 samples] loss: 0.364.\neval loss: 0.632, accuracy: 69.964% [17491/25000]\nsentence_max_len_40-embedding-128-model-<class 'torch.nn.modules.rnn.RNN'>-layers-5-lr-0.00001000-batch_size-1024-dropout-0.10\n[1 seconds](epoch: 0/500)[25000 samples] loss: 0.696.\neval loss: 0.696, accuracy: 50.476% [12619/25000]\n[78 seconds](epoch: 50/500)[1275000 samples] loss: 0.689.\neval loss: 0.694, accuracy: 51.360% [12840/25000]\n[155 seconds](epoch: 100/500)[2525000 samples] loss: 0.681.\neval loss: 0.693, accuracy: 51.660% [12915/25000]\n[232 seconds](epoch: 150/500)[3775000 samples] loss: 0.667.\neval loss: 0.693, accuracy: 52.484% [13121/25000]\n[309 seconds](epoch: 200/500)[5025000 samples] loss: 0.623.\neval loss: 0.668, accuracy: 60.120% [15030/25000]\n[386 seconds](epoch: 250/500)[6275000 samples] loss: 0.580.\neval loss: 0.657, accuracy: 62.236% [15559/25000]\n[462 seconds](epoch: 300/500)[7525000 samples] loss: 0.576.\neval loss: 0.648, accuracy: 63.580% [15895/25000]\n[539 seconds](epoch: 350/500)[8775000 samples] loss: 0.578.\neval loss: 0.641, accuracy: 64.376% [16094/25000]\n[616 seconds](epoch: 400/500)[10025000 samples] loss: 0.474.\neval loss: 0.638, accuracy: 65.036% [16259/25000]\n[693 seconds](epoch: 450/500)[11275000 samples] loss: 0.491.\neval loss: 0.641, accuracy: 65.836% [16459/25000]\n[769 seconds](epoch: 499/500)[12500000 samples] loss: 0.415.\neval loss: 0.646, accuracy: 66.276% [16569/25000]\nsentence_max_len_40-embedding-128-model-<class 'torch.nn.modules.rnn.RNN'>-layers-10-lr-0.00001000-batch_size-1024-dropout-0.10\n[1 seconds](epoch: 0/500)[25000 samples] loss: 0.693.\neval loss: 0.696, accuracy: 49.828% [12457/25000]\n[78 seconds](epoch: 50/500)[1275000 samples] loss: 0.691.\neval loss: 0.694, accuracy: 50.808% [12702/25000]\n[154 seconds](epoch: 100/500)[2525000 samples] loss: 0.678.\neval loss: 0.693, accuracy: 52.352% [13088/25000]\n[231 seconds](epoch: 150/500)[3775000 samples] loss: 0.632.\neval loss: 0.661, accuracy: 61.512% [15378/25000]\n[308 seconds](epoch: 200/500)[5025000 samples] loss: 0.608.\neval loss: 0.650, accuracy: 63.472% [15868/25000]\n[386 seconds](epoch: 250/500)[6275000 samples] loss: 0.602.\neval loss: 0.642, accuracy: 64.792% [16198/25000]\n[463 seconds](epoch: 300/500)[7525000 samples] loss: 0.531.\neval loss: 0.635, accuracy: 65.608% [16402/25000]\n[539 seconds](epoch: 350/500)[8775000 samples] loss: 0.514.\neval loss: 0.629, accuracy: 66.652% [16663/25000]\n[616 seconds](epoch: 400/500)[10025000 samples] loss: 0.472.\neval loss: 0.628, accuracy: 67.204% [16801/25000]\n[693 seconds](epoch: 450/500)[11275000 samples] loss: 0.455.\neval loss: 0.630, accuracy: 67.652% [16913/25000]\n[769 seconds](epoch: 499/500)[12500000 samples] loss: 0.445.\neval loss: 0.637, accuracy: 68.056% [17014/25000]\nsentence_max_len_40-embedding-128-model-<class 'torch.nn.modules.rnn.LSTM'>-layers-5-lr-0.00001000-batch_size-1024-dropout-0.10\n[2 seconds](epoch: 0/500)[25000 samples] loss: 0.692.\neval loss: 0.696, accuracy: 50.060% [12515/25000]\n[105 seconds](epoch: 50/500)[1275000 samples] loss: 0.689.\neval loss: 0.692, accuracy: 52.204% [13051/25000]\n[209 seconds](epoch: 100/500)[2525000 samples] loss: 0.679.\neval loss: 0.682, accuracy: 55.884% [13971/25000]\n[313 seconds](epoch: 150/500)[3775000 samples] loss: 0.582.\neval loss: 0.637, accuracy: 63.768% [15942/25000]\n[416 seconds](epoch: 200/500)[5025000 samples] loss: 0.551.\neval loss: 0.612, accuracy: 66.480% [16620/25000]\n[518 seconds](epoch: 250/500)[6275000 samples] loss: 0.508.\neval loss: 0.597, accuracy: 68.380% [17095/25000]\n[621 seconds](epoch: 300/500)[7525000 samples] loss: 0.490.\neval loss: 0.596, accuracy: 69.396% [17349/25000]\n[725 seconds](epoch: 350/500)[8775000 samples] loss: 0.452.\neval loss: 0.602, accuracy: 69.964% [17491/25000]\n[829 seconds](epoch: 400/500)[10025000 samples] loss: 0.370.\neval loss: 0.617, accuracy: 70.080% [17520/25000]\n[932 seconds](epoch: 450/500)[11275000 samples] loss: 0.354.\neval loss: 0.634, accuracy: 70.216% [17554/25000]\n[1034 seconds](epoch: 499/500)[12500000 samples] loss: 0.332.\neval loss: 0.660, accuracy: 70.068% [17517/25000]\nsentence_max_len_40-embedding-128-model-<class 'torch.nn.modules.rnn.LSTM'>-layers-10-lr-0.00001000-batch_size-1024-dropout-0.10\n[1 seconds](epoch: 0/500)[25000 samples] loss: 0.693.\neval loss: 0.693, accuracy: 50.472% [12618/25000]\n[103 seconds](epoch: 50/500)[1275000 samples] loss: 0.689.\neval loss: 0.692, accuracy: 52.488% [13122/25000]\n[206 seconds](epoch: 100/500)[2525000 samples] loss: 0.665.\neval loss: 0.677, accuracy: 57.216% [14304/25000]\n[310 seconds](epoch: 150/500)[3775000 samples] loss: 0.596.\neval loss: 0.625, accuracy: 65.212% [16303/25000]\n[413 seconds](epoch: 200/500)[5025000 samples] loss: 0.537.\neval loss: 0.605, accuracy: 67.284% [16821/25000]\n[517 seconds](epoch: 250/500)[6275000 samples] loss: 0.537.\neval loss: 0.596, accuracy: 68.540% [17135/25000]\n[621 seconds](epoch: 300/500)[7525000 samples] loss: 0.497.\neval loss: 0.596, accuracy: 69.468% [17367/25000]\n[725 seconds](epoch: 350/500)[8775000 samples] loss: 0.415.\neval loss: 0.603, accuracy: 69.884% [17471/25000]\n[827 seconds](epoch: 400/500)[10025000 samples] loss: 0.380.\neval loss: 0.617, accuracy: 69.936% [17484/25000]\n[930 seconds](epoch: 450/500)[11275000 samples] loss: 0.379.\neval loss: 0.637, accuracy: 69.960% [17490/25000]\n[1031 seconds](epoch: 499/500)[12500000 samples] loss: 0.381.\neval loss: 0.662, accuracy: 70.012% [17503/25000]\n"
    }
   ],
   "source": [
    "# put everything together\n",
    "import time\n",
    "from data_util import *\n",
    "from models import *\n",
    "from trainer import classification_trainer\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# config = TextCNNConfig(\n",
    "#             criteria=nn.CrossEntropyLoss, optimizer=optim.Adam, lr=0.00003, epochs=1000, \n",
    "#             batch_size=1024, num_classes=2, sentence_max_length=30, word_embedding_length=128, \n",
    "#             activation=F.relu, dropout=0.1, conv_layer_sizes=[3,4,5,6,7]\n",
    "#         )\n",
    "\n",
    "def run(rnn_type, num_layers):\n",
    "    config = RNNConfig(\n",
    "        rnn_type=rnn_type,\n",
    "        criteria=nn.CrossEntropyLoss, optimizer=optim.Adam, lr=0.00001, epochs=500, \n",
    "        batch_size=1024, num_classes=2, sentence_max_length=40, word_embedding_length=128, \n",
    "        num_layers=num_layers, activation=F.relu, dropout=0.1,\n",
    "    )\n",
    "    print(config)\n",
    "\n",
    "    pos_train_data_folder = os.path.join(dataset_folder_path, \"train/pos\")\n",
    "    neg_train_data_folder = os.path.join(dataset_folder_path, \"train/neg\")\n",
    "    train_dataset = MovieReviewDataset(config, pos_train_data_folder, neg_train_data_folder, word_to_id, \n",
    "                                transform=transforms.Compose([\n",
    "                                    CutOrPadTransform(config), WordsToIdsTransform(config, word_to_id)\n",
    "                                ]))\n",
    "\n",
    "    pos_test_data_folder = os.path.join(dataset_folder_path, \"test/pos\")\n",
    "    neg_test_data_folder = os.path.join(dataset_folder_path, \"test/neg\")\n",
    "    test_dataset = MovieReviewDataset(config, pos_test_data_folder, neg_test_data_folder, word_to_id, \n",
    "                                transform=transforms.Compose([\n",
    "                                    CutOrPadTransform(config), WordsToIdsTransform(config, word_to_id)\n",
    "                                ]))\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config.batch_size)\n",
    "\n",
    "    # model = TextCNN(config, len(word_to_id)).to(device)\n",
    "    model = RNN(config, len(word_list)).to(config.device)\n",
    "\n",
    "    classification_trainer.train(model, config, train_dataloader, test_dataloader)\n",
    "\n",
    "\n",
    "run(nn.GRU, num_layers=1)\n",
    "run(nn.RNN, num_layers=1)\n",
    "run(nn.LSTM, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}